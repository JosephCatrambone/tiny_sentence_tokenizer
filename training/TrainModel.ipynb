{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea61d31-5588-4b3d-a491-906794cc3d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94ea08c6-53d1-4183-9b04-a12ed46c878e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/joseph/RustSource/tiny_sentence_tokenizer/training/wandb/run-20240628_153021-ha0yy54k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/josephc/tiny_sentence_tokenizer/runs/ha0yy54k' target=\"_blank\">classic-disco-6</a></strong> to <a href='https://wandb.ai/josephc/tiny_sentence_tokenizer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/josephc/tiny_sentence_tokenizer' target=\"_blank\">https://wandb.ai/josephc/tiny_sentence_tokenizer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/josephc/tiny_sentence_tokenizer/runs/ha0yy54k' target=\"_blank\">https://wandb.ai/josephc/tiny_sentence_tokenizer/runs/ha0yy54k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/josephc/tiny_sentence_tokenizer/runs/ha0yy54k?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fbea5bb61d0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 256\n",
    "HIDDEN_SIZE = 16\n",
    "NUM_EPOCHS = 10\n",
    "CONTEXT_SIZE = 24\n",
    "\n",
    "EXTRA_MODEL_PARAMS = dict(hidden_size=HIDDEN_SIZE, num_heads=4, embedding_size=32, num_outputs=2)\n",
    "\n",
    "experiment_config = {\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"architecture\": \"transformer\",\n",
    "    \"dataset\": \"synthetic-wiki-one-meelyun-sentences\",\n",
    "    \"epochs\": NUM_EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"hidden_size\": HIDDEN_SIZE,\n",
    "    \"context_size\": CONTEXT_SIZE,\n",
    "    \"extra_model_params\": EXTRA_MODEL_PARAMS\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    project=\"tiny_sentence_tokenizer\",  # https://wandb.ai/josephc/tiny_sentence_tokenizer\n",
    "    config=experiment_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a543ea6-133e-4403-bb17-924954a8b569",
   "metadata": {},
   "source": [
    "# Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5d5fc7f-e32e-4c29-b824-99e71d4b9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import bz2\n",
    "import os\n",
    "import random\n",
    "from typing import List, Optional\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SentenceSplitDataset:\n",
    "    def __init__(self, path_to_sentences: os.PathLike, context_size: int, sentence_breaks: List[str] = [\" \", \"  \", \"\\n\", \"\\r\\n\", \"\\t\", \"\", \"\\n\\n\\n\\n\", \"    \"]):\n",
    "        self.context_size = context_size\n",
    "        self.characters_read = 0\n",
    "        self.sentence_offsets = list()\n",
    "        self.sentences = list()\n",
    "        self.sentence_breaks = sentence_breaks\n",
    "        with bz2.open(path_to_sentences, 'rt') as fin:\n",
    "            for line in fin:\n",
    "                self.sentence_offsets.append(self.characters_read)\n",
    "                line = line.strip()\n",
    "                self.sentences.append(line)\n",
    "                self.characters_read += len(line)+1\n",
    "    def __len__(self):\n",
    "        #return len(self.sentences)\n",
    "        return self.characters_read\n",
    "    def get_sentence(self, idx: int) -> str:\n",
    "        return self.sentences[idx]\n",
    "    def get_sentence_idx_with_character(self, idx: int) -> int:\n",
    "        return bisect.bisect_right(self.sentence_offsets, idx)-1\n",
    "    def get_sentence_with_character(self, idx: int, context: Optional[int] = None) -> str:\n",
    "        # Map the index to the sentence.\n",
    "        sentence_idx = self.get_sentence_idx_with_character(idx)\n",
    "        sentence = self.sentences[sentence_idx]\n",
    "        position_in_sentence = idx - self.sentence_offsets[sentence_idx]\n",
    "        assert position_in_sentence >= 0\n",
    "        if context is None:\n",
    "            return sentence\n",
    "        return sentence[max(0, position_in_sentence-context):position_in_sentence], sentence[position_in_sentence:position_in_sentence+context]\n",
    "    def __getitem__(self, idx: int):\n",
    "        prefix, suffix = self.get_sentence_with_character(idx, context=self.context_size)\n",
    "        end_of_sentence = len(suffix) == 0\n",
    "        suffix += random.choice(self.sentence_breaks) + self.get_sentence(self.get_sentence_idx_with_character(idx+1))\n",
    "        prefix = prefix.rjust(self.context_size)[-self.context_size:]\n",
    "        suffix = suffix.ljust(self.context_size)[:self.context_size]\n",
    "        #suffix = suffix.ljust(self.context_size)\n",
    "        return prefix, suffix, end_of_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c22e09c-9465-42b2-a68a-e278ebf7d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SentenceSplitDataset(path_to_sentences=\"./one_meelyun_sentences.bz2\", context_size=CONTEXT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee2482b3-ce54-4a18-90aa-dd539a0774e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('                        ', 'County and municipal cou', False)\n",
      "('            The Exchange', ' Building opened in 1854', False)\n",
      "('pened in 1854, part of t', 'he building was later us', False)\n",
      "('ened in 1854, part of th', 'e building was later use', False)\n",
      "('ned in 1854, part of the', ' building was later used', False)\n",
      "69: ('lected every four years.', '  The by-census indicate', True)\n",
      "215: (' by more than 1 million.', \" 'On the Marble Cliffs' \", True)\n",
      "378: (\"ion in Hitler's Germany.\", '\\tHomer brief description', True)\n",
      "423: (\"ion in the 'Iliad'Homer.\", '\\n\\n\\n\\nPublic hearings were', True)\n",
      "545: ('co, and Washington, D.C.', '\\tOn July 10, both forces', True)\n",
      "596: ('ced each other in Kyoto.', \"    Monmouth's status as\", True)\n",
      "733: (' November 2002 election.', '\\n\\n\\n\\nOpiates are hypothes', True)\n",
      "796: ('ate aggression and rage.', ' The town celebrated its', True)\n",
      "840: (' its centennial in 2004.', '  In 1681 Anthony Ashley', True)\n",
      "964: (' or recourse to a trial.', \" Crater Lake's features \", True)\n",
      "1202: ('n from July to October).', '    The dam blocked the ', True)\n",
      "1284: ('upstream spawning areas.', '  Antisubmarine measures', True)\n",
      "1396: ('waters since July 1942 .', '\\n\\n\\n\\nOn February 28, 1986', True)\n",
      "1624: ('was left of the station.', '\\nHowever, the coal depos', True)\n",
      "1702: (' amounts of methane gas.', '\\n\\n\\n\\nWhile slightly more ', True)\n",
      "1821: ('gressive foreign policy.', '\\r\\nIn Solomon, the CU wou', True)\n"
     ]
    }
   ],
   "source": [
    "print(ds[0])\n",
    "print(ds[5001])\n",
    "print(ds[5036])\n",
    "print(ds[5037])\n",
    "print(ds[5038])\n",
    "for i in range(0, 2000):\n",
    "    a, b, c = ds[i]\n",
    "    if c:\n",
    "        print(f\"{i}: {ds[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2d011584-12a5-4838-8fdb-7cee8bcce7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import bz2\n",
    "import os\n",
    "import random\n",
    "from typing import List, Optional\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BalancedEOSDataset:\n",
    "    def __init__(self, path_to_sentences: os.PathLike, context_size: int, sentence_breaks: List[str] = [\" \", \"  \", \"\\n\", \"\\r\\n\", \"\\t\", \"\", \"\\n\\n\\n\\n\", \"    \",]):\n",
    "        self.context_size = context_size\n",
    "        self.sentences = list()\n",
    "        self.sentence_breaks = sentence_breaks\n",
    "        with bz2.open(path_to_sentences, 'rt') as fin:\n",
    "            for line in fin:\n",
    "                line = line.strip()\n",
    "                self.sentences.append(line)\n",
    "    def __len__(self):\n",
    "        return (len(self.sentences)-2)*2  # Double since evens will be 'not end of sentence'.\n",
    "    def __getitem__(self, idx: int):\n",
    "        end_of_sentence = (idx%2 != 0)\n",
    "        if not end_of_sentence:\n",
    "            sentence = self.sentences[idx//2]\n",
    "            split_point = random.randint(1, len(sentence)-1)\n",
    "            prefix = sentence[:split_point]\n",
    "            suffix = sentence[split_point:]\n",
    "            prefix = prefix.rjust(self.context_size)[-self.context_size:]\n",
    "            suffix = suffix.ljust(self.context_size)[:self.context_size]\n",
    "            return prefix, suffix, False\n",
    "        else:\n",
    "            prefix = (self.sentences[idx//2].rjust(self.context_size+1))[-self.context_size:]\n",
    "            suffix = (random.choice(self.sentence_breaks) + self.sentences[(idx//2)+1].ljust(self.context_size))[:self.context_size]\n",
    "            return prefix, suffix, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "329c5ae2-9285-47d9-b16d-9149a7581681",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = BalancedEOSDataset(path_to_sentences=\"./one_meelyun_sentences.bz2\", context_size=CONTEXT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "775efbc9-983a-403a-99f6-2cfff1a7df3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ty and municipal council', 's are popularly elected ', False)\n",
      "('e President Dick Cheney.', '\\n\\n\\n\\nSabine Baring-Gould ', True)\n",
      "('ere were 36 airports and', ' one heliport.          ', False)\n",
      "('rports and one heliport.', '\\n\\n\\n\\nKennedy later said t', True)\n",
      "('Kennedy later said that ', 'his four day-visit to Ir', False)\n"
     ]
    }
   ],
   "source": [
    "print(ds[0])\n",
    "print(ds[5001])\n",
    "print(ds[5036])\n",
    "print(ds[5037])\n",
    "print(ds[5038])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd0e866-ed81-40bb-8b58-9a75fcaced6d",
   "metadata": {},
   "source": [
    "# Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0901334-6714-46dc-bb56-3a7b4517421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, List, Union\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(256, hidden_size)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def strings_to_tensor(sentences: list) -> torch.Tensor:\n",
    "        longest = max([len(sentence.encode(\"utf-8\")) for sentence in sentences])\n",
    "        out = torch.zeros(len(sentences), longest, 256)\n",
    "        for batch_idx, s in enumerate(sentences):\n",
    "            s = s.encode(\"utf-8\")\n",
    "            for byte_idx in range(len(s)):\n",
    "                out[batch_idx, byte_idx, int(s[byte_idx])] = 1.0\n",
    "        return out\n",
    "\n",
    "    def forward(self, x, hidden = None):\n",
    "        hidden = F.tanh(self.i2h(x) + self.h2h(hidden))\n",
    "        output = self.h2o(hidden)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def _init_hidden(self, height: int = 1):\n",
    "        return torch.zeros(height, self.hidden_size)\n",
    "\n",
    "    def split_paragraph_iter(self, p: str, min_threshold: Optional[float] = None) -> Iterator[str]:\n",
    "        self.eval()\n",
    "        h = self._init_hidden()\n",
    "        i = torch.zeros(1, 256)\n",
    "        last_sentence = \"\"\n",
    "        for character in p:\n",
    "            last_sentence += character\n",
    "            # Convert character to a byte.\n",
    "            b = character.encode(\"utf-8\")\n",
    "            for b_value in b:\n",
    "                i[0, int(b_value)] = 1.0\n",
    "                out, h = self.forward(i, h)\n",
    "                i[0, int(b_value)] = 0.0\n",
    "            out = out.cpu().numpy()\n",
    "            if out[0,1] >= out[0,0] or (min_threshold is not None and out[0,1] > min_threshold):\n",
    "                yield last_sentence\n",
    "                last_sentence = \"\"\n",
    "        yield last_sentence\n",
    "\n",
    "\n",
    "def run_inference(m, prefix: List[str], suffix: Optional[List[str]]):\n",
    "    prefix = RNN.strings_to_tensor(prefix).to(DEVICE)\n",
    "    if suffix is not None:\n",
    "        suffix = RNN.strings_to_tensor(suffix).to(DEVICE)\n",
    "    hidden = m._init_hidden().to(DEVICE)\n",
    "    for i in range(0, prefix.shape[1]):\n",
    "        out, hidden = m(prefix[:,i,:], hidden)\n",
    "    if suffix is not None:\n",
    "        for i in range(0, suffix.shape[1]):\n",
    "            out, hidden = m(suffix[:,i,:], hidden)\n",
    "    return out\n",
    "\n",
    "\n",
    "n_hidden = HIDDEN_SIZE\n",
    "n_categories = 2\n",
    "model = RNN(n_hidden, n_categories)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2707b139-7937-4924-86f5-f4acb24b0f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, List, Union\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from unidecode import unidecode\n",
    "\n",
    "class TFSentenceSplit(nn.Module):\n",
    "    def __init__(self, hidden_size: int, num_heads: int, embedding_size: int, num_outputs: int):\n",
    "        super().__init__()\n",
    "        self.position_embedding = nn.Embedding(num_embeddings=256, embedding_dim=embedding_size)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_size, nhead=num_heads, batch_first=True)\n",
    "        self.inference_head = nn.Linear(embedding_size, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Assumes x is batch first like a normal, sensible person.\n",
    "        # out = self.encode_layer(torch.rand(batch_size, seq_length, embedding_size))\n",
    "        # Use torch.LongTensor to encode.\n",
    "        x = self.position_embedding(x)\n",
    "        x = self.encoder_layer(x) # Out: [batch_size, seq_len, embedding_size]\n",
    "        x = self.inference_head(x)\n",
    "        x = F.softmax(x, dim=-1)\n",
    "        return x[:,-1,:].squeeze(1)\n",
    "\n",
    "    @staticmethod\n",
    "    def strings_to_tensor(sentences: list) -> torch.Tensor:\n",
    "        longest = max([len(sentence.encode(\"utf-8\")) for sentence in sentences])\n",
    "        out = torch.zeros((len(sentences), longest), dtype=torch.int64)  # torch.LongTensor\n",
    "        for batch_idx, s in enumerate(sentences):\n",
    "            s = s.rjust(longest).encode(\"utf-8\")[-longest:]  # Pad the left with spaces so it's aligned, then convert to bytes and truncate.\n",
    "            for byte_idx in range(len(s)):\n",
    "                out[batch_idx, byte_idx] = int(s[byte_idx])\n",
    "        return out\n",
    "\n",
    "def run_inference(m, prefix: List[str], suffix: List[str]):\n",
    "    prefix = TFSentenceSplit.strings_to_tensor(prefix).to(DEVICE)\n",
    "    #suffix = TFSentenceSplit.strings_to_tensor(suffix).to(DEVICE)\n",
    "    return m.forward(prefix)\n",
    "\n",
    "model = TFSentenceSplit(**EXTRA_MODEL_PARAMS)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2e1a77-d8e3-49c8-9484-e35857d655bd",
   "metadata": {},
   "source": [
    "# Evaluation and Training Prep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8e384879-1a7d-4d06-b6ca-65b646838ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "total_examples = len(ds)  # Hack -- dunno the total example count.\n",
    "train_size = int(total_examples*0.7)\n",
    "validation_size = int(total_examples*0.1)\n",
    "test_size = total_examples - (train_size + validation_size)\n",
    "train_ds, validate_ds, test_ds = torch.utils.data.random_split(ds, [train_size, validation_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3bd259da-7f93-4d9d-97fd-fdaf8dc5ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validate_dataloader = DataLoader(validate_ds, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5f9157e1-d65d-4def-bc1c-678e7cbc5619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tpr_fpr_tnr_fnr(predictions_logits, ground_truth_labels):\n",
    "    # Assume predictions are a tensor of shape [batch, 2], same with ground truth.\n",
    "    # Assume predictions are NORMALIZED along axis=1 ([_,0], [_,1]).\n",
    "    # Assume [:,1] means 'yes, this is a break'.\n",
    "    with torch.no_grad():\n",
    "        pred = predictions_logits.cpu().numpy()\n",
    "        gt = ground_truth_labels.cpu().numpy()\n",
    "        \n",
    "        tpr = 0\n",
    "        fpr = 0\n",
    "        tnr = 0\n",
    "        fnr = 0\n",
    "        for idx in range(0, pred.shape[0]):\n",
    "            if gt[idx] < 0.5 or gt[idx] == False: # GT: Negative\n",
    "                if pred[idx,0] > pred[idx,1]: # Pred: Negative\n",
    "                    tnr += 1\n",
    "                else: # Pred: Positive\n",
    "                    fpr += 1\n",
    "            else: # GT: Positive\n",
    "                if pred[idx,0] > pred[idx,1]: # Pred: Negative:\n",
    "                    fnr += 1\n",
    "                else: # Pred: Positive\n",
    "                    tpr += 1\n",
    "        return tpr, fpr, tnr, fnr\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8d53297c-495e-43a2-ae18-ba9fa60542ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 4, 1, 0)\n",
      "(4, 0, 0, 1)\n",
      "tensor([[7.6257e-06, 9.9999e-01]], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "(0, 0, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "assert compute_tpr_fpr_tnr_fnr(torch.tensor([[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0]]), torch.tensor([0, 1, 0, 1])) == (1, 1, 1, 1)\n",
    "print(compute_tpr_fpr_tnr_fnr(torch.tensor([[0.1, 0.9], [0.2, 0.8], [0.3, 0.7], [0.4, 0.6], [0.6, 0.4]]), torch.tensor([0, 0, 0, 0, 0])))\n",
    "print(compute_tpr_fpr_tnr_fnr(torch.tensor([[0.1, 0.9], [0.2, 0.8], [0.3, 0.7], [0.4, 0.6], [0.6, 0.4]]), torch.tensor([1, 1, 1, 1, 1])))\n",
    "print(run_inference(model, [\"Only a.\"], []))\n",
    "print(compute_tpr_fpr_tnr_fnr(run_inference(model, [\"Only a test\", \"Mostly a test\", \"Ignore me\"], []), torch.tensor([0, 1, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "862cf75d-100b-4901-956f-3062b9950fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 79, 110, 108, 121,  32,  97,  32, 116, 101, 115, 116,  46],\n",
      "        [ 32,  32,  32,  32,  77, 111, 115, 116, 108, 121,  32,  97],\n",
      "        [ 32,  32,  32,  32,  32,  32,  73, 103, 110, 111, 114, 101]])\n",
      "tensor([[7.0584e-06, 9.9999e-01]], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "(1, 0, 2, 0)\n"
     ]
    }
   ],
   "source": [
    "print(TFSentenceSplit.strings_to_tensor([\"Only a test.\", \"Mostly a\", \"Ignore\"]))\n",
    "print(run_inference(model, [\"Only a test.\"], []))\n",
    "print(compute_tpr_fpr_tnr_fnr(run_inference(model, [\"Only a test.\", \"Mostly a\", \"Ignore\"], []), torch.tensor([1, 0, 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf0e588-18e8-478a-a5a4-4b35f8df0746",
   "metadata": {},
   "source": [
    "# Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "01d9b145-37f7-4674-99ae-003bc60f044a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d736f9d0b2454f7db1dba7d57a509faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29de841bba254c6e98ff45fe08dc5999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2499: 0.0012829395431837563\n",
      "0: 4999: 0.0012842619629034535\n",
      "END OF EPOCH 0: 7.023348012357019 train loss\n",
      "END OF EPOCH 0: 1.003268651664257 validation loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858cc111a72e4e4f8fd0063bced43187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 2499: 0.0012785414394387651\n",
      "1: 4999: 0.0012735982540847894\n",
      "END OF EPOCH 1: 6.985950689762831 train loss\n",
      "END OF EPOCH 1: 0.9949951990274712 validation loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c383f47797fd46848883d9797744faa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: 2499: 0.0012766401339488929\n",
      "2: 4999: 0.0012784149233055961\n",
      "END OF EPOCH 2: 6.948916549794376 train loss\n",
      "END OF EPOCH 2: 0.9929292330052704 validation loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c055cec17b740aea43ffbb57a5bb2e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: 2499: 0.00125973992400006\n",
      "3: 4999: 0.0012639339528977417\n",
      "END OF EPOCH 3: 6.940024675917812 train loss\n",
      "END OF EPOCH 3: 0.9912436854792759 validation loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc9f105916847a58dee25e5329342f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: 2499: 0.0012602235510088462\n",
      "4: 4999: 0.0012700707688301776\n",
      "END OF EPOCH 4: 6.931345159187913 train loss\n",
      "END OF EPOCH 4: 0.9907174380496144 validation loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b7b0815a3a46919450dbd4e85016bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: 2499: 0.0012708762592163613\n",
      "5: 4999: 0.0012662896689727863\n",
      "END OF EPOCH 5: 6.92873289482668 train loss\n",
      "END OF EPOCH 5: 0.9905290466267616 validation loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405882290c09423e9aa30693085a0aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6: 2499: 0.0012666972434059946\n",
      "6: 4999: 0.0012735800933405099\n",
      "END OF EPOCH 6: 6.928655483876355 train loss\n",
      "END OF EPOCH 6: 0.9917419753037393 validation loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0eb93830574b6b8aec4b7176750d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7: 2499: 0.0012828623781695162\n",
      "7: 4999: 0.0012689588803401516\n",
      "END OF EPOCH 7: 6.927611568477005 train loss\n",
      "END OF EPOCH 7: 0.9910406979033723 validation loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835213c6b4d14422beada079a3a19269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8: 2499: 0.0012641329340382943\n",
      "8: 4999: 0.0012601744025184038\n",
      "END OF EPOCH 8: 6.9264642025809735 train loss\n",
      "END OF EPOCH 8: 0.9905455211410299 validation loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855f1ff7e147425997df0c63f9612aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9: 2499: 0.0012674037941124432\n",
      "9: 4999: 0.0012662072212573457\n",
      "END OF EPOCH 9: 6.926161372219212 train loss\n",
      "END OF EPOCH 9: 0.9894104808336124 validation loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>false_negative_rate</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>false_positive_rate</td><td>▁▆▆▆▆▆▇▆▆▆▅▆▆▆▆▆▆▆▆▆▆▅▆▆▆█▆▆▆▆▆▆▆▆▆▆▇▆▆▆</td></tr><tr><td>positives_seen</td><td>▁▂▅▂▅▇▁▄▅▇▁▄▆█▂▅▆█▂▅▇▁▄▆▇▁▄▆█▂▅▇█▂▅▇▁▄▆█</td></tr><tr><td>true_negative_rate</td><td>█▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>true_positive_rate</td><td>▁████████████████████████▇██████████▇███</td></tr><tr><td>validation_loss</td><td>█▄▃▂▂▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.00123</td></tr><tr><td>false_negative_rate</td><td>0.00742</td></tr><tr><td>false_positive_rate</td><td>0.49816</td></tr><tr><td>positives_seen</td><td>691005</td></tr><tr><td>true_negative_rate</td><td>0.00355</td></tr><tr><td>true_positive_rate</td><td>0.49086</td></tr><tr><td>validation_loss</td><td>0.98941</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-disco-6</strong> at: <a href='https://wandb.ai/josephc/tiny_sentence_tokenizer/runs/ha0yy54k' target=\"_blank\">https://wandb.ai/josephc/tiny_sentence_tokenizer/runs/ha0yy54k</a><br/> View project at: <a href='https://wandb.ai/josephc/tiny_sentence_tokenizer' target=\"_blank\">https://wandb.ai/josephc/tiny_sentence_tokenizer</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240628_153021-ha0yy54k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from tqdm import tqdm\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "lowest_loss = 1e10\n",
    "best_counts = 0\n",
    "\n",
    "for epoch in trange(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    examples_seen = 0\n",
    "    positives_seen = 0\n",
    "    total_train_loss = 0.0\n",
    "    running_train_loss = 0.0\n",
    "    validation_loss = 0.0\n",
    "    tpr, tnr, fpr, fnr = 0, 0, 0, 0\n",
    "    for batch_idx, (pre, suf, label) in tqdm(enumerate(train_dataloader)):\n",
    "        label = (torch.Tensor(label) * 1).to(DEVICE)\n",
    "        out = run_inference(model, pre, suf)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        examples_seen += BATCH_SIZE\n",
    "        positives_seen += torch.sum(label).item()\n",
    "        per_example_loss = loss.item()/BATCH_SIZE\n",
    "        total_train_loss += per_example_loss\n",
    "        running_train_loss = running_train_loss * 0.9 + per_example_loss * 0.1\n",
    "        batch_tp, batch_fp, batch_tn, batch_fn = compute_tpr_fpr_tnr_fnr(out, label)\n",
    "        tpr += batch_tp\n",
    "        tnr += batch_tn\n",
    "        fpr += batch_fp\n",
    "        fnr += batch_fn\n",
    "        if batch_idx % 100 == 0:\n",
    "            rate = tpr+tnr+fpr+fnr\n",
    "            wandb.log({\n",
    "                \"batch_loss\": per_example_loss, \n",
    "                \"false_positive_rate\": fpr/rate, \n",
    "                \"true_positive_rate\": tpr/rate,\n",
    "                \"false_negative_rate\": fnr/rate,\n",
    "                \"true_negative_rate\": tnr/rate,\n",
    "                \"positives_seen\": positives_seen,\n",
    "            }, commit=(batch_idx%1000)==0)\n",
    "            tpr, tnr, fpr, fnr = 0, 0, 0, 0\n",
    "        if (batch_idx+1) % 2500 == 0:\n",
    "            print(f\"{epoch}: {batch_idx}: {running_train_loss}\")\n",
    "    print(f\"END OF EPOCH {epoch}: {total_train_loss} train loss\")\n",
    "    model.eval()\n",
    "    for batch_idx, (pre, suf, label) in enumerate(validate_dataloader):\n",
    "        label = (torch.Tensor(label) * 1).to(DEVICE)\n",
    "        out = run_inference(model, pre, suf)\n",
    "        loss = loss_fn(out, label)\n",
    "        validation_loss += loss.item()/BATCH_SIZE\n",
    "    wandb.log({\"validation_loss\": validation_loss})\n",
    "    print(f\"END OF EPOCH {epoch}: {validation_loss} validation loss\")\n",
    "    torch.save(model, f\"checkpoint_epoch_{epoch}.pt\")\n",
    "    if validation_loss < lowest_loss:\n",
    "        lowest_loss = validation_loss\n",
    "        torch.save(model, f\"best_{best_counts}.pt\")\n",
    "        best_counts += 1\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9cd0f5-3410-4d62-86e8-3c349fdde81b",
   "metadata": {},
   "source": [
    "Lifted from https://damdid2022.frccsc.ru/files/article/DAMDID_2022_paper_2646.pdf\n",
    "Zavyalova, Martynyuk, and Samarev\n",
    "\n",
    "\"Testing will be performed on 5840 sentences from “The GUM Corpus” [16].\"\n",
    "\n",
    "|Tool Name                |tp  |fp | tn   |fn  |accuracy|error|precision|recall|f1   |\n",
    "|---                      |--- |---|---   |--- |---     |---  |---      |---   |---  |\n",
    "|Sentencize.jl            |6330|254|107813|1078|0.99    |0.01 |0.96     |0.85  |0.905|\n",
    "|NLTK                     |6269|283|107787|1139|0.99    |0.01 |0.96     |0.85  |0.898|\n",
    "|OpenNLP                  |6255|276|107791|1153|0.99    |0.01 |0.96     |0.84  |0.897|\n",
    "|CoreNLP                  |6278|362|107786|1130|0.99    |0.01 |0.95     |0.85  |0.894|\n",
    "|WordTokenizers.jl        |6140|264|107809|1268|0.99    |0.01 |0.96     |0.83  |0.889|\n",
    "|Spacy (Dependency parser)|6631|934|107268|777 |0.99    |0.01 |0.88     |0.90  |0.886|\n",
    "|Spacy (Rule-based)       |6183|994|107531|1225|0.98    |0.02 |0.86     |0.83  |0.848|\n",
    "|SimpleSplitter           |5760|772|107847|1648|0.98    |0.02 |0.88     |0.78  |0.826|\n",
    "|Julia split()            |5760|878|107780|1648|0.98    |0.02 |0.87     |0.78  |0.820|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "503471d0-b86f-4676-80e1-4f062f363f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw:\n",
      "('councils are popularly e', 'lected every four years.', False)\n",
      "DL raw:\n",
      "omemade drum as a child.\n",
      "tensor(True)\n",
      "Processed:\n",
      "TP: 124  TN: 128  FP: 0  FN: 4\n",
      "!!!\n",
      "Sent: S YOU HAVE A REFERENCE!!\n",
      "Model guess: EOS: False\n",
      "Truth: EOS: True\n",
      "\n",
      "!!!\n",
      "Sent:  of the cross to be .178\n",
      "Model guess: EOS: False\n",
      "Truth: EOS: True\n",
      "\n",
      "!!!\n",
      "Sent: or 'Intervention Order '\n",
      "Model guess: EOS: False\n",
      "Truth: EOS: True\n",
      "\n",
      "!!!\n",
      "Sent:  do país' - Papo de Bola\n",
      "Model guess: EOS: False\n",
      "Truth: EOS: True\n",
      "\n",
      "Total errors: 4\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(\"Raw:\")\n",
    "print(ds[0])\n",
    "print(\"DL raw:\")\n",
    "for pre, suf, label in train_dataloader:\n",
    "    print(pre[0])\n",
    "    print(label[0])\n",
    "    break\n",
    "print(\"Processed:\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for pre, suf, label in train_dataloader:\n",
    "        label = (torch.Tensor(label) * 1).to(DEVICE)\n",
    "        out = run_inference(model, pre, suf)\n",
    "        tp, fp, tn, fn = compute_tpr_fpr_tnr_fnr(out, label)\n",
    "        loss = loss_fn(out, label).cpu().numpy()\n",
    "        out = out.cpu().numpy()\n",
    "        confidence = numpy.abs(out[:, 0] - out[:, 1])\n",
    "        print(f\"TP: {tp}  TN: {tn}  FP: {fp}  FN: {fn}\")\n",
    "        errors = 0\n",
    "        for idx in range(out.shape[0]):\n",
    "            model_guess_eos = out[idx,1]>out[idx,0]\n",
    "            gt_eos = label[idx]>0.5\n",
    "            if model_guess_eos != gt_eos:\n",
    "                print(\"!!!\")\n",
    "                errors += 1\n",
    "                print(f\"Sent: {pre[idx]}\")\n",
    "                print(f\"Model guess: EOS: {model_guess_eos}\")\n",
    "                print(f\"Truth: EOS: {gt_eos}\")\n",
    "                print()\n",
    "        print(f\"Total errors: {errors}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "cb15e897-2748-4bb3-b3fe-9b8712aaeeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model:\n",
    "placeholder_x = torch.zeros([BATCH_SIZE, CONTEXT_SIZE], dtype=torch.int64)\n",
    "model.eval().to('cpu')\n",
    "out = model(placeholder_x)\n",
    "torch.onnx.export(\n",
    "    model, \n",
    "    placeholder_x,\n",
    "    f\"sentence_tokenizer_v6_{CONTEXT_SIZE}x256.onnx\",\n",
    "    export_params=True,        # store the trained parameter weights inside the model file\n",
    "    opset_version=14,          # the ONNX version to export the model to\n",
    "    do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "    input_names = ['input'],   # the model's input names\n",
    "    output_names = ['output'], # the model's output names\n",
    "    dynamic_axes={'input' : {0 : 'batch_size'}, 'output' : {0 : 'batch_size'}}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ee230b4f-dc30-4a80-bded-8466a8919f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joseph/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:130: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OnnxExporterError",
     "evalue": "Failed to export the model to ONNX. Generating SARIF report at 'report_dynamo_export.sarif'. SARIF is a standard format for the output of static analysis tools. SARIF logs can be loaded in VS Code SARIF viewer extension, or SARIF web viewer (https://microsoft.github.io/sarif-web-component/). Please report a bug on PyTorch Github: https://github.com/pytorch/pytorch/issues",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:1195\u001b[0m, in \u001b[0;36mdynamo_export\u001b[0;34m(model, export_options, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExporter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_export_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:961\u001b[0m, in \u001b[0;36mExporter.export\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    958\u001b[0m fx_interpreter \u001b[38;5;241m=\u001b[39m fx_onnx_interpreter\u001b[38;5;241m.\u001b[39mFxOnnxInterpreter(\n\u001b[1;32m    959\u001b[0m     diagnostic_context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mdiagnostic_context\n\u001b[1;32m    960\u001b[0m )\n\u001b[0;32m--> 961\u001b[0m onnxscript_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfx_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfx_graph_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43monnxfunction_dispatcher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnxfunction_dispatcher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_level_debug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop_level_debug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;66;03m# NOTE: Filter out the initializers with fake tensors when it's fake_mode exporting.\u001b[39;00m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;66;03m# Otherwise, the ONNX exporter will fail: RuntimeError: basic_string::_M_construct null\u001b[39;00m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;66;03m# not valid.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# Concrete data is expected to be filled for those initializers later during `ExportOutput.save`.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py:151\u001b[0m, in \u001b[0;36mdiagnose_call.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_and_raise_if_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiag\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/infra/context.py:366\u001b[0m, in \u001b[0;36mDiagnosticContext.log_and_raise_if_error\u001b[0;34m(self, diagnostic)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m diagnostic\u001b[38;5;241m.\u001b[39msource_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m diagnostic\u001b[38;5;241m.\u001b[39msource_exception\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m RuntimeErrorWithDiagnostic(diagnostic)\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py:135\u001b[0m, in \u001b[0;36mdiagnose_call.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     return_values \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m diag\u001b[38;5;241m.\u001b[39mlog_section(logging\u001b[38;5;241m.\u001b[39mINFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn values\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:534\u001b[0m, in \u001b[0;36mFxOnnxInterpreter.run\u001b[0;34m(self, fx_graph_module, onnxfunction_dispatcher, op_level_debug, parent_onnxscript_graph)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m fx_graph_module\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mnodes:\n\u001b[0;32m--> 534\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfx_graph_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m            \u001b[49m\u001b[43monnxfunction_dispatcher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m            \u001b[49m\u001b[43mop_level_debug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m            \u001b[49m\u001b[43monnxscript_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m            \u001b[49m\u001b[43monnxscript_tracer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfx_name_to_onnxscript_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m diagnostic\u001b[38;5;241m.\u001b[39mlog_section(logging\u001b[38;5;241m.\u001b[39mDEBUG, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mONNX Graph:\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py:151\u001b[0m, in \u001b[0;36mdiagnose_call.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_and_raise_if_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiag\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/infra/context.py:366\u001b[0m, in \u001b[0;36mDiagnosticContext.log_and_raise_if_error\u001b[0;34m(self, diagnostic)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m diagnostic\u001b[38;5;241m.\u001b[39msource_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m diagnostic\u001b[38;5;241m.\u001b[39msource_exception\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m RuntimeErrorWithDiagnostic(diagnostic)\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py:135\u001b[0m, in \u001b[0;36mdiagnose_call.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     return_values \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m diag\u001b[38;5;241m.\u001b[39mlog_section(logging\u001b[38;5;241m.\u001b[39mINFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn values\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:439\u001b[0m, in \u001b[0;36mFxOnnxInterpreter.run_node\u001b[0;34m(self, node, fx_graph_module, onnxfunction_dispatcher, op_level_debug, onnxscript_graph, onnxscript_tracer, fx_name_to_onnxscript_value)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m node\u001b[38;5;241m.\u001b[39mop \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall_module\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43monnxscript_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfx_name_to_onnxscript_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43monnxscript_tracer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfx_graph_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43monnxfunction_dispatcher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop_level_debug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m node\u001b[38;5;241m.\u001b[39mop \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:763\u001b[0m, in \u001b[0;36mFxOnnxInterpreter.call_module\u001b[0;34m(self, node, parent_onnxscript_graph, fx_name_to_onnxscript_value, tracer, root_fx_graph_module, onnxfunction_dispatcher, op_level_debug)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    760\u001b[0m     sub_module, torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mGraphModule\n\u001b[1;32m    761\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msub_module must be a torch.fx.GraphModule, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(sub_module)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for node \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 763\u001b[0m sub_onnxscript_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[43msub_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monnxfunction_dispatcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_level_debug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_onnxscript_graph\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    767\u001b[0m onnx_args, _ \u001b[38;5;241m=\u001b[39m _wrap_fx_args_as_onnxscript_args(\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28mlist\u001b[39m(node\u001b[38;5;241m.\u001b[39margs), {}, fx_name_to_onnxscript_value, tracer\n\u001b[1;32m    769\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py:151\u001b[0m, in \u001b[0;36mdiagnose_call.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_and_raise_if_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiag\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/infra/context.py:366\u001b[0m, in \u001b[0;36mDiagnosticContext.log_and_raise_if_error\u001b[0;34m(self, diagnostic)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m diagnostic\u001b[38;5;241m.\u001b[39msource_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m diagnostic\u001b[38;5;241m.\u001b[39msource_exception\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m RuntimeErrorWithDiagnostic(diagnostic)\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py:135\u001b[0m, in \u001b[0;36mdiagnose_call.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     return_values \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m diag\u001b[38;5;241m.\u001b[39mlog_section(logging\u001b[38;5;241m.\u001b[39mINFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn values\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:534\u001b[0m, in \u001b[0;36mFxOnnxInterpreter.run\u001b[0;34m(self, fx_graph_module, onnxfunction_dispatcher, op_level_debug, parent_onnxscript_graph)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m fx_graph_module\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mnodes:\n\u001b[0;32m--> 534\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfx_graph_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m            \u001b[49m\u001b[43monnxfunction_dispatcher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m            \u001b[49m\u001b[43mop_level_debug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m            \u001b[49m\u001b[43monnxscript_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m            \u001b[49m\u001b[43monnxscript_tracer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfx_name_to_onnxscript_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m diagnostic\u001b[38;5;241m.\u001b[39mlog_section(logging\u001b[38;5;241m.\u001b[39mDEBUG, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mONNX Graph:\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py:151\u001b[0m, in \u001b[0;36mdiagnose_call.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_and_raise_if_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiag\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/infra/context.py:366\u001b[0m, in \u001b[0;36mDiagnosticContext.log_and_raise_if_error\u001b[0;34m(self, diagnostic)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m diagnostic\u001b[38;5;241m.\u001b[39msource_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m diagnostic\u001b[38;5;241m.\u001b[39msource_exception\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m RuntimeErrorWithDiagnostic(diagnostic)\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/diagnostics/infra/decorator.py:135\u001b[0m, in \u001b[0;36mdiagnose_call.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     return_values \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m diag\u001b[38;5;241m.\u001b[39mlog_section(logging\u001b[38;5;241m.\u001b[39mINFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn values\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:428\u001b[0m, in \u001b[0;36mFxOnnxInterpreter.run_node\u001b[0;34m(self, node, fx_graph_module, onnxfunction_dispatcher, op_level_debug, onnxscript_graph, onnxscript_tracer, fx_name_to_onnxscript_value)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m node\u001b[38;5;241m.\u001b[39mop \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall_function\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 428\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43monnxscript_tracer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfx_name_to_onnxscript_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43monnxfunction_dispatcher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop_level_debug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfx_graph_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m node\u001b[38;5;241m.\u001b[39mop \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall_method\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:660\u001b[0m, in \u001b[0;36mFxOnnxInterpreter.call_function\u001b[0;34m(self, node, onnxscript_tracer, fx_name_to_onnxscript_value, onnxfunction_dispatcher, op_level_debug, fx_graph_module)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;66;03m# Assign type and shape from fx graph.\u001b[39;00m\n\u001b[0;32m--> 660\u001b[0m \u001b[43m_fill_tensor_shape_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;66;03m# One fx node could produce multiple outputs (e.g., tuple of tensors); in\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# that case, v is a tuple of TorchScriptTensors.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/fx/fx_onnx_interpreter.py:244\u001b[0m, in \u001b[0;36m_fill_tensor_shape_type\u001b[0;34m(onnxscript_values, name, expected_values)\u001b[0m\n\u001b[1;32m    241\u001b[0m     onnxscript_value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m=\u001b[39m fx_type_utils\u001b[38;5;241m.\u001b[39mfrom_sym_value_to_torch_dtype(\n\u001b[1;32m    242\u001b[0m         expected_value\n\u001b[1;32m    243\u001b[0m     )\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m fx_type_utils\u001b[38;5;241m.\u001b[39mis_torch_complex_dtype(\u001b[43mexpected_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m):\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# Like torch.view_as_real, we flatten complex tensors to real tensors with\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;66;03m# additional last dimension of 2\u001b[39;00m\n\u001b[1;32m    247\u001b[0m     onnxscript_value\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;241m*\u001b[39m[\n\u001b[1;32m    249\u001b[0m             dim \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dim, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    253\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'dtype'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOnnxExporterError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[228], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m placeholder_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros([\u001b[38;5;241m1\u001b[39m, CONTEXT_SIZE], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m exporter \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamo_export\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplaceholder_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m exporter\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_tokenizer_v6_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONTEXT_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mx256_dynamo.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/transformers/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:1206\u001b[0m, in \u001b[0;36mdynamo_export\u001b[0;34m(model, export_options, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m resolved_export_options\u001b[38;5;241m.\u001b[39mdiagnostic_context\u001b[38;5;241m.\u001b[39mdump(sarif_report_path)\n\u001b[1;32m   1199\u001b[0m message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to export the model to ONNX. Generating SARIF report at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msarif_report_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSARIF is a standard format for the output of static analysis tools. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease report a bug on PyTorch Github: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_PYTORCH_GITHUB_ISSUES_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1205\u001b[0m )\n\u001b[0;32m-> 1206\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OnnxExporterError(\n\u001b[1;32m   1207\u001b[0m     ExportOutput\u001b[38;5;241m.\u001b[39m_from_failure(e, resolved_export_options\u001b[38;5;241m.\u001b[39mdiagnostic_context),\n\u001b[1;32m   1208\u001b[0m     message,\n\u001b[1;32m   1209\u001b[0m ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOnnxExporterError\u001b[0m: Failed to export the model to ONNX. Generating SARIF report at 'report_dynamo_export.sarif'. SARIF is a standard format for the output of static analysis tools. SARIF logs can be loaded in VS Code SARIF viewer extension, or SARIF web viewer (https://microsoft.github.io/sarif-web-component/). Please report a bug on PyTorch Github: https://github.com/pytorch/pytorch/issues"
     ]
    }
   ],
   "source": [
    "placeholder_x = torch.zeros([1, CONTEXT_SIZE], dtype=torch.int64)\n",
    "model.eval().to('cpu')\n",
    "exporter = torch.onnx.dynamo_export(model, placeholder_x)\n",
    "exporter.save(f\"sentence_tokenizer_v6_{CONTEXT_SIZE}x256_dynamo.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
